{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d6W4cZX9etf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnv7YJ7y-Y4_",
        "outputId": "af1e6126-83eb-4de6-a382-78f5678ca617"
      },
      "source": [
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> wordnet\n",
            "    Downloading package wordnet to /root/nltk_data...\n",
            "      Package wordnet is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n",
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Package stopwords is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkQkdeEn-Y7d"
      },
      "source": [
        "dt=pd.read_csv(\"/content/SPAM.csv\", encoding= 'unicode_escape')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "r2A_Qge1-Y91",
        "outputId": "13cb42a6-3f50-4a72-967a-f7bd33f9fd82"
      },
      "source": [
        "dt['spam']=np.where(dt['type']=='spam',1,0)\n",
        "dt.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                               text  spam\n",
              "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
              "1   ham                      Ok lar... Joking wif u oni...     0\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
              "3   ham  U dun say so early hor... U c already then say...     0\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2wC5ORI-ZAP",
        "outputId": "5bae17f4-ab54-4ed9-c052-95b746c8ed2d"
      },
      "source": [
        "dt['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Go until jurong point, crazy.. Available only ...\n",
              "1                          Ok lar... Joking wif u oni...\n",
              "2      Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      U dun say so early hor... U c already then say...\n",
              "4      Nah I don't think he goes to usf, he lives aro...\n",
              "                             ...                        \n",
              "111             What is the plural of the noun research?\n",
              "112                      Going for dinner.msg you after.\n",
              "113    I'm ok wif it cos i like 2 try new things. But...\n",
              "114    GENT! We are trying to contact you. Last weeke...\n",
              "115                      Wa, ur openin sentence very for\n",
              "Name: text, Length: 116, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VADIfzN8-ZCv"
      },
      "source": [
        "def token(text):\n",
        "  return text.split()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi3UsxBE-ZFJ"
      },
      "source": [
        "dt['text']=dt['text'].apply(token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXnrZb75-ZHj",
        "outputId": "a9a26993-e419-46c0-c732-5e1278818eff"
      },
      "source": [
        "dt['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      [Go, until, jurong, point,, crazy.., Available...\n",
              "1                   [Ok, lar..., Joking, wif, u, oni...]\n",
              "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
              "3      [U, dun, say, so, early, hor..., U, c, already...\n",
              "4      [Nah, I, don't, think, he, goes, to, usf,, he,...\n",
              "                             ...                        \n",
              "111    [What, is, the, plural, of, the, noun, research?]\n",
              "112                [Going, for, dinner.msg, you, after.]\n",
              "113    [I'm, ok, wif, it, cos, i, like, 2, try, new, ...\n",
              "114    [GENT!, We, are, trying, to, contact, you., La...\n",
              "115               [Wa,, ur, openin, sentence, very, for]\n",
              "Name: text, Length: 116, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZsGONst-ZKC"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "porter=SnowballStemmer(\"english\",ignore_stopwords=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOgLbbGk-ZMb"
      },
      "source": [
        "def stemming(text):\n",
        "  return[porter.stem(word) for word in text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbtKA7TXCrBz"
      },
      "source": [
        "dt[\"text\"]=dt[\"text\"].apply(stemming)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MStrJ2woCrEf",
        "outputId": "32261d0b-38d4-45c3-b8dd-77884ecdbf6c"
      },
      "source": [
        "dt['text'][3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['u',\n",
              " 'dun',\n",
              " 'say',\n",
              " 'so',\n",
              " 'earli',\n",
              " 'hor...',\n",
              " 'u',\n",
              " 'c',\n",
              " 'alreadi',\n",
              " 'then',\n",
              " 'say...']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8CyJVzbCrHa"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer= WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMCSwvbpCrJi"
      },
      "source": [
        "def lemmit(text):\n",
        "  return[lemmatizer.lemmatize(word, pos='a')for word in text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8euKZ1cCrL3"
      },
      "source": [
        "dt[\"text\"]=dt[\"text\"].apply(lemmit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYTGzMCGCrOM",
        "outputId": "09be41ee-b8f2-41c1-d039-e390978b6055"
      },
      "source": [
        "dt['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      [go, until, jurong, point,, crazy.., avail, on...\n",
              "1                     [ok, lar..., joke, wif, u, oni...]\n",
              "2      [free, entri, in, 2, a, wkli, comp, to, win, f...\n",
              "3      [u, dun, say, so, earli, hor..., u, c, alreadi...\n",
              "4      [nah, i, don't, think, he, goe, to, usf,, he, ...\n",
              "                             ...                        \n",
              "111    [what, is, the, plural, of, the, noun, research?]\n",
              "112                   [go, for, dinner.msg, you, after.]\n",
              "113    [i'm, ok, wif, it, cos, i, like, 2, tri, new, ...\n",
              "114    [gent!, we, are, tri, to, contact, you., last,...\n",
              "115                [wa,, ur, openin, sentenc, veri, for]\n",
              "Name: text, Length: 116, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc66v93ZCrQL"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words=stopwords.words(\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgPvhNeHCrYp"
      },
      "source": [
        "def stop_word(text):\n",
        "  review=[word for word in text if not word in stop_words]\n",
        "  return review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU0VygW0Crbo"
      },
      "source": [
        "dt['text']=dt['text'].apply(stop_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "m9bUiQCnEdqW",
        "outputId": "21ec423b-0a30-4c29-a90f-b6b7e40617ba"
      },
      "source": [
        "dt['text']=dt['text'].apply(' '.join)\n",
        "dt.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go jurong point, crazy.. avail onli bugi n gre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joke wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entri 2 wkli comp win fa cup final tkts 2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say earli hor... u c alreadi say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah think goe usf, live around though</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                               text  spam\n",
              "0   ham  go jurong point, crazy.. avail onli bugi n gre...     0\n",
              "1   ham                        ok lar... joke wif u oni...     0\n",
              "2  spam  free entri 2 wkli comp win fa cup final tkts 2...     1\n",
              "3   ham          u dun say earli hor... u c alreadi say...     0\n",
              "4   ham              nah think goe usf, live around though     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vBVSazyCrhI"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8PFqMnyEdnv"
      },
      "source": [
        "tfidf=TfidfVectorizer()\n",
        "y=dt.spam.values\n",
        "x=tfidf.fit_transform(dt['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyKv5dnMEdtE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=1,test_size=0.2,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT10_JDIIGv_",
        "outputId": "92adb881-3543-4067-efd6-6887896122f1"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_log= accuracy_score(y_pred,y_test)*100\n",
        "print('Accuracy: ', acc_log)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  87.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stBrYiz0IsW5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogVIpwIjIsZr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEzlv7uRIscC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oajOjMOIshC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}